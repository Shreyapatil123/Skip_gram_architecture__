{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvFhF_nmCLcw"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipGram(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(SkipGram, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.linear = nn.Linear(embedding_dim, vocab_size)\n",
        "\n",
        "    def forward(self, target):\n",
        "        embedded = self.embedding(target)\n",
        "        predicted = self.linear(embedded)\n",
        "        return predicted\n"
      ],
      "metadata": {
        "id": "imtjw9ydCOdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(text, window_size=2):\n",
        "    data = []\n",
        "    for i in range(len(text)):\n",
        "        for j in range(max(0, i - window_size), min(len(text), i + window_size + 1)):\n",
        "            if i != j:\n",
        "                data.append((text[i], text[j]))\n",
        "    return data"
      ],
      "metadata": {
        "id": "iKQsPAQQC_z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(data, vocab_size, embedding_dim, epochs=10, learning_rate=0.001):\n",
        "    model = SkipGram(vocab_size, embedding_dim)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        random.shuffle(data)\n",
        "        total_loss = 0\n",
        "        for target_word, context_word in data:\n",
        "            model.zero_grad()\n",
        "            target_idx = word_to_idx[target_word]\n",
        "            context_idx = word_to_idx[context_word]\n",
        "            target_tensor = torch.LongTensor([target_idx])\n",
        "            context_tensor = torch.LongTensor([context_idx])\n",
        "            output = model(target_tensor)\n",
        "            loss = criterion(output, context_tensor)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(data)}\")\n",
        "\n",
        "    return model.embedding.weight.data.numpy()\n"
      ],
      "metadata": {
        "id": "yUidbtFqDFZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "text = \"natural language processing is fun and interesting\".split()\n",
        "data = prepare_data(text)\n",
        "word_to_idx = {word: idx for idx, word in enumerate(set(text))}\n",
        "idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n",
        "vocab_size = len(word_to_idx)\n",
        "embedding_dim = 50\n",
        "\n",
        "word_embeddings = train_model(data, vocab_size, embedding_dim)\n",
        "\n",
        "# Print word embeddings\n",
        "for i in range(len(word_embeddings)):\n",
        "    word = idx_to_word[i]\n",
        "    embedding = word_embeddings[i]\n",
        "    print(f\"{word}: {embedding}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrrWQs4iDM0H",
        "outputId": "3e0cfc4d-2653-4de0-97a9-0ba632fc6355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 2.0539676655422556\n",
            "Epoch 2, Loss: 2.0235471075231377\n",
            "Epoch 3, Loss: 1.9947397654706782\n",
            "Epoch 4, Loss: 1.9674148776314475\n",
            "Epoch 5, Loss: 1.941401801326058\n",
            "Epoch 6, Loss: 1.9167742891745134\n",
            "Epoch 7, Loss: 1.8933285854079507\n",
            "Epoch 8, Loss: 1.8710150664502925\n",
            "Epoch 9, Loss: 1.849716305732727\n",
            "Epoch 10, Loss: 1.8294603662057356\n",
            "is: [-0.6531595   0.33865714 -0.3624338  -1.018374   -0.95648164 -1.3083072\n",
            "  0.7871692  -0.7319469  -1.0730002  -1.6556005   0.9644851  -1.4050752\n",
            " -0.31364802 -1.1399194  -1.1470544   0.40877202 -0.44794974  0.6461737\n",
            " -2.7971988  -0.56297785 -0.4739546   0.784937    0.10262039 -0.9652856\n",
            "  0.32698455 -0.14238454  0.32448795  2.059471   -0.5894113   0.86387897\n",
            "  1.7739866  -0.4988416  -1.5006317  -0.33302632 -0.10389426 -1.139832\n",
            " -0.9651045  -0.17161614 -1.4075046  -2.345691   -0.6596367  -3.0982912\n",
            "  1.3073208   0.85510087 -1.553278   -0.8986698  -0.6245564   0.8722838\n",
            " -0.12938458  0.7257798 ]\n",
            "natural: [ 0.5534912   1.4498534  -0.11348208 -0.850385    0.44610938 -1.632181\n",
            " -0.5743444  -0.72379214  1.0708013  -0.36093092 -1.0394732  -1.1440523\n",
            " -1.3754649  -1.2630509   0.41491368  1.1928028   0.3178947  -0.20684497\n",
            "  1.6205873   0.5099091  -0.90644294 -1.1689578   0.5727605  -0.7552178\n",
            " -1.6012787  -0.48392975 -1.237586    0.18104467  1.6032587  -2.2931972\n",
            " -0.06652786 -0.46423018 -0.49822575  0.19072707 -0.58642745 -2.1263812\n",
            " -0.49791595 -1.4879353  -0.84801507 -0.52456874 -0.05993031 -2.1770177\n",
            "  1.0177329  -0.56108916  0.62268496 -0.32861784  0.14184712 -0.99527985\n",
            "  0.64743245 -1.3106582 ]\n",
            "interesting: [ 0.6659906   0.8826288   0.2437293   0.15283905 -0.7103956  -0.29796907\n",
            "  0.02127223  0.96621436 -1.1349299   0.12326405 -1.8138573   0.74724376\n",
            " -1.0808231   0.268784   -1.559937   -0.818801    0.00935289  0.48282748\n",
            "  1.0813344   1.7441761   0.61496973  0.11521051 -0.82284576 -0.45976365\n",
            "  1.0628316   0.8698619   1.5877671   0.19692373 -3.3194735  -1.0377141\n",
            "  0.2189588   0.24324296  1.5105467  -0.23316969  0.06744113  0.27399027\n",
            " -0.4734792  -0.41256386 -0.8236395   0.61309433 -1.3577985   0.25141403\n",
            " -0.31095922 -1.9368409   0.79273623  0.52687716 -1.0233194   1.58093\n",
            " -0.6658209   1.2017567 ]\n",
            "fun: [-0.24670786 -1.0614105   0.15650018  0.6021229  -0.95369595  0.8589882\n",
            "  1.7767034  -0.8142508   0.560597    0.08479548 -0.07230858  0.96100783\n",
            " -1.1220206  -2.8660765  -0.08090524  0.56296897 -0.11377864 -0.61202836\n",
            " -0.3701819   0.5489276  -1.8960743  -1.2506961  -0.8167528   2.4126601\n",
            "  0.13452476  0.72536135  0.4307142   0.6686295  -1.0179448   1.3351418\n",
            "  1.3155297   0.5610346  -1.5004008   0.90933436  1.0269446  -2.2551637\n",
            "  0.04069911 -1.0949064   0.24717551  1.8702749  -0.0897815   0.5739991\n",
            "  0.8599285  -0.9186693  -0.98874176 -0.5181109  -1.2514383   0.11544353\n",
            " -0.3203662   0.13302663]\n",
            "processing: [ 0.08803662  0.42048788 -2.0059803  -0.40757996 -0.24404219 -2.0303922\n",
            " -0.59721565  0.8372363  -0.30694363 -0.7839612  -0.01113597 -0.39493877\n",
            " -0.55740553  0.7876869  -0.10554048 -0.9707834   2.6031218   0.56024086\n",
            "  2.2229543  -0.9962967  -0.15644784  0.21728218  0.23205818  0.6289512\n",
            "  0.7377075  -1.183625   -0.88376474  2.0832582  -0.7515925   0.64647496\n",
            " -0.28851023 -0.09580848 -0.75641876 -0.5084745  -0.867462   -0.14722094\n",
            " -0.8866919  -0.788874   -0.65135825 -0.8177301   0.11334355 -0.16768244\n",
            " -0.14216028  0.96425354  1.3961041  -0.08250985  0.06963997  0.3725121\n",
            "  0.07278338  1.1631874 ]\n",
            "language: [-0.01746519  0.31285188  0.13197902 -0.7482716  -1.2537148  -1.0322362\n",
            "  0.51147234 -0.06131256  1.5238286   1.1639299  -0.48136795  0.7871836\n",
            "  0.9653316  -0.10969254 -1.3225107  -0.6224934   1.7068965   0.23886783\n",
            " -0.7811428  -0.20824204  0.436761   -2.0690598  -0.6426624  -0.82059205\n",
            "  0.5448648  -2.469181    0.43567365 -0.27534446 -0.80959886 -0.6093079\n",
            "  0.6183356   0.88142127  1.660623   -0.66494983  0.07315999  0.53584266\n",
            "  0.9396588   0.8023794  -0.15722777 -0.10104605  0.28358918 -1.773514\n",
            " -1.470904   -2.4656286   0.6708475   0.9840818   1.5028875  -0.3700096\n",
            " -0.9943946   0.65045583]\n",
            "and: [-0.32796428  0.28953552 -1.9126666  -0.38827583  2.1034095   2.3838875\n",
            " -1.4209756   0.2283134   0.51229626 -1.3512341  -1.1056397   0.8554227\n",
            "  0.04321689  0.02492564 -0.3762322   0.9588814   0.12130636  0.79205287\n",
            "  0.88424313 -0.68670857 -0.4667052   0.9113356  -1.6799544  -1.1249886\n",
            "  0.4218793  -0.7832043   0.09997717 -0.19621125 -1.1377074  -1.514725\n",
            "  1.5122831  -1.0702655   1.3719447  -0.3211139   0.05266445  0.6644309\n",
            " -0.05711715  0.52646005 -0.5520183   1.8718958  -0.19836137  0.9902134\n",
            " -0.44485658  0.3518692  -0.13858402  0.02037456  1.0016125   1.3722587\n",
            " -0.34601524 -1.5491086 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BLmPQLrwDTFs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}